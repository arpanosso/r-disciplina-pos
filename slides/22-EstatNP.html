<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Estatística Não Paramétrica</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alan R Panosso alan.panosso@unesp.br" />
    <script src="libs/header-attrs-2.27/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Estatística Não Paramétrica
]
.subtitle[
## Estatística e Experimentação no Ambiente R
]
.author[
### Alan R Panosso <a href="mailto:alan.panosso@unesp.br" class="email">alan.panosso@unesp.br</a>
]
.institute[
### Pós-graduação Agronomia (Ciência do Solo)
]
.date[
### 09 a 20 de dezembro de 2024
]

---


## Teste Não Paramétrico

Quando amostras são retiradas de populações com distribuições desconhecidas, não é apropriado o uso dos testes `\(z\)` ou `\(t\)`. 

Indicações destas distribuições são quando a **moda é próxima do fim da amplitude** ou quando algumas observações tem **valores mais extremos** do que outros. 

Testes *não paramétricos* são apropriados para estas amostras porque **nenhuma distribuição teórica é assumida** . Muitos destes testes comparam as populações por meio de alguma medida central como a **mediana** e a **moda**. 

A transformação **ordenação** dos dados também é utilizada. 

O uso desta transformação diminui a importância da distribuição e a influência de valores extremos nas amostras. 

---

A hipótese nula é que **não existe efeito de grupos**. 

É assumido que **as distribuições dos grupos são iguais**, mas não necessariamente conhecidas. 


A aplicação do teste t-student para duas amostras requer que as duas populações amostradas sejam normais e com variâncias iguais (homocedásticas). 


Felizmente, a maioria dos testes mais comuns empregados são suficientemente robustos para desvios das hipóteses teóricas. 

Entretanto, existe uma grande variedade de métodos que não requerem a estimação da variância ou da média e não impõem hipóteses sobre os parâmetros.   

Estes testes são denominados de **testes não paramétricos**.

---

Como estes métodos também não fazem suposições sobre a natureza da distribuição (isto é, normalidade) das populações amostradas, eles são as vezes denominados **de testes livres de distribuições**. 

![](../img/tnp01.png)

---

### O teste do sinal (The Sign Test):

1) Deseja-se escolher entre dois equipamentos de laboratórios, `\(A\)` e `\(B\)`, capazes de realizar `\(12\)` análises diferentes e que a rapidez de execução seja um ponto a ser considerado.

![](../img/tnp02.png)

---
### O teste do sinal (The Sign Test):

`$$\begin{cases}
H_0: \text{as populações para os grupos são a mesma} \\
H_1: \text{as observações para os grupo não são as mesmas}
\end{cases}$$`

sob `\(H_0\)` verdadeira  é de se esperar uma ocorrência de `\(N/2\)` sinais negativos e `\(N/2\)` sinais positivos, ou seja, o problema se resume em testar se `\(f( - )\)` ou `\(f( + )\)` seja igual a `\(1/2\)`. assim calcula-se a estatística `\(Z\)` definida por:

$$
Z = \frac{p-0,5}{\sqrt{\frac{N}{2}}} \sim \mathcal{N}(0, 1)
$$

Temos :
 `\(p = f( - ) = 2/12=1/6\)` e   `\(zc = -2,28\)`, sendo que o valor crítico de `\(|Z_{0,05}| =1,96\)`. Logo pode-se afirmar, com base nos dados amostrais, que os equipamentos `\(A\)` e `\(B\)` diferem entre si significativamente quanto ao tempo do resultado para `\(\alpha = 0,05\)`.

---

### Resolvendo no R

`$$\begin{cases}
H_0: \text{as populações para os grupos são a mesma} \\
H_1: \text{as observações para os grupo não são as mesmas}
\end{cases}$$`


```r
A&lt;-c(40,22,22,45,68,33,48,75,41,44,47,31)
B&lt;-c(29,16,29,41,61,24,54,68,36,36,42,25)
D&lt;-A-B
x&lt;-sum(D&lt;0)
N&lt;-length(D)
prop.test(x,N,p=.5,alternative="t")
```

```
## 
## 	1-sample proportions test with continuity correction
## 
## data:  x out of N, null probability 0.5
## X-squared = 4.0833, df = 1, p-value = 0.04331
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.02940911 0.49118581
## sample estimates:
##         p 
## 0.1666667
```
---

2) Em determinada variedade de cana-de-açúcar, o comprimento médio do terceiro internódio é de `\(22\;cm\)`. Admitindo esse como um fator discriminante e querendo averiguar se a cada de um talhão pertence a esta variedade, foram tomadas nove amostras de `\(6\)` colmos cada, obtendo-se os seguintes comprimentos médios do terceiro internódio:

`$$\begin{cases}
H_0: \mu = 22 \;cm \\
H_1: \mu \neq 22 \;cm
\end{cases}$$`

&lt;img src="../img/tnp03.png" width="400px" style="display: block; margin: auto;" /&gt;

---

&lt;img src="../img/tnp04.png" width="700px" style="display: block; margin: auto;" /&gt;

---

### Resolvendo no R


```r
Z&lt;-c(23.30, 22.40, 21.10, 22.60, 22.20, 23.50, 22.70, 22.80, 23.00)
D&lt;-Z-22
x&lt;-sum(D&lt;0)
N&lt;-length(D)
prop.test(x, N, p=.5, alternative="t")
```

```
## Warning in prop.test(x, N, p = 0.5, alternative = "t"): Aproximação do
## qui-quadrado pode estar incorreta
```

```
## 
## 	1-sample proportions test with continuity correction
## 
## data:  x out of N, null probability 0.5
## X-squared = 4, df = 1, p-value = 0.0455
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.005827557 0.493297984
## sample estimates:
##         p 
## 0.1111111
```

---

### Dados ordinais 

Os dados ordinais raramente têm uma distribuição normal, então para analisa-los, são usados testes não-paramétricos. Os testes de  significância mais comumente aplicados em dados ordinais são os seguintes:

![](../img/tnp05.png)

---

#### O teste de "Wilcoxon Signed-Rank" para locação

As vezes desejamos testar uma H0 sobre a média populacional, mas por alguma razão **(amostras pequenas,  n&lt;30, de uma população que sabidamente não tem distribuição normal, e o Teorema do Limite Central não é aplicável)**  nem a estatística `\(\mathcal{Z}\)` ou a  `\(t-student\)` são testes estatísticos apropriados.

Como vimos anteriormente, **o teste do sinal** pode ser usado quando dados consistem de uma amostra simples ou quando temos dados pareados. Entretanto, o Teste do Sinal (The Sign Test) pode não ser adequado visto que **ele não utiliza toda a informação contida nos dados**. Um procedimento mais apropriado pode ser o teste de **Wilcoxon signed-rank** (Teste das Ordens Assinaladas), o qual **faz uso da magnitude da diferença entre as medidas** e parâmetro de locação do que simplesmente os sinais das diferenças. 


O teste de **Wilcoxon** para locação é baseado nas seguintes hipóteses sobre os dados:


  + a amostra é aleatória  
  + a variável é contínua  
  + a população é simetricamente distribuída em torno da sua média    

---

**As hipóteses estatísticas**  

`$$a) \begin{cases}
H_0: \mu = \mu_0  \\
H_1: \mu \neq \mu_0
\end{cases}$$`

`$$b) \begin{cases}
H_0: \mu \ge \mu_0  \\
H_1: \mu &lt; \mu_0
\end{cases}$$`

`$$c) \begin{cases}
H_0: \mu \le \mu_0  \\
H_1: \mu &gt; \mu_0
\end{cases}$$`

Os cálculos do  teste será ilustrado por meio de um exemplo

---

Exemplo: Os dados abaixo referem-se a frequência cardíaca pós operatória de 15 animais operados do coração. Os resultados foram:

Podemos concluir, com base nestes dados de que a média populacional é diferente de `\(5,05\)` ?

`$$\begin{cases}
H_0: \mu = 5,05  \\
H_1: \mu \neq 5,05
\end{cases}$$`


&lt;img src="../img/tnp06.png" width="500px" style="display: block; margin: auto;" /&gt;


Neste exemplo comparamos `\(T = 34\)` com um valor tabelado de `\(T_t\)` . Se `\(T \le T_{( n, \alpha/2)}\)`


---
### Resolvendo no R


```r
fc&lt;-c(4.91, 4.10, 6.74, 7.27, 7.42, 7.50, 6.56,
	4.64, 5.98, 3.14, 3.23, 5.80, 6.17, 5.39, 5.77)
di&lt;-fc-5.05
posto&lt;-rank(abs(di))
sinal&lt;-ifelse(di&gt;0,posto,-1*posto)
df&lt;-data.frame(fc, di, posto, sinal)
sum(posto[di&gt;0])
```

```
## [1] 86
```

```r
sum(posto[di&lt;0])
```

```
## [1] 34
```

---

```r
hist(fc,col="gray",ylim=c(0,5));box()
abline(v=mean(fc),col=2,lwd=2,lty=2)
abline(v=median(fc),col=4,lwd=2,lty=2)
legend(3.5,4,c("Media","Mediana"),col=c(2,4),lty=c(2,2),lwd=2)
```

![](22-EstatNP_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

---


```r
wilcox.test(fc,mu=5.05,alternative="t")
```

```
## 
## 	Wilcoxon signed rank exact test
## 
## data:  fc
## V = 86, p-value = 0.1514
## alternative hypothesis: true location is not equal to 5.05
```

Não rejeitamos a hipótese da nulidade e podemos concluir que a média populacional não é diferente de `\(5,05\)`.

---

#### Teste da Soma dos Postos de Wilcoxon (The Wilcoxon Rank Sum Test).

O teste da soma dos postos de **Wilcoxon** é o teste não paramétrico para comparar dois grupos independentes. 

Ele é um teste não paramétrico análogo **ao teste t** para duas amostras e as vezes é referido como o **Mann-Whitney U test**. 

A hipótese `\(H_0\)` é que as populações são as mesmas. 

A única **suposição** para estes testes é que as observações são independentes. 

Na prática, este teste é usado com variáveis cujas medidas são ordinais, intervalos, e razões. 

As hipóteses necessárias para a aplicação do teste

  + as duas amostras de tamanhos n e m são amostras independentes e aleatórias de suas respectivas populações   
  + a escala das medidas é pelo menos ordinal  
  + se as populações diferem, elas diferem somente com respeito às suas medianas.  

---

Exemplo de aplicação do **Wilcoxon Rank Sum Test** (alternativa mais comumente usada para o teste t para amostras independentes).

Considere os resultados de dois tratamentos A e B, respectivamente, e obteve-se os resultados expressos abaixo.

![](../img/tnp07.png)
Hipóteses estatísticas

`$$\begin{cases}
H_0: \tilde{m}_A = \tilde{m}_B  \\
H_1: \tilde{m}_A \neq \tilde{m}_B
\end{cases}$$`

O teste estatístico

`$$T = S - \frac{n(n+1)}{2}$$`

---

Soma-se os postos dos tratamento A:

Tratamento `\(A = ( 5,5 + 2 + 4 + 1 + 3 ) = 15,5  =  S\)`. Então, o valor da estatística é 

`$$T = 15,5 - \frac{5(6+1)}{2} = 0,5$$`

a qual é menor do que o valor tabelado de `\(T = 5\)` dado em tabela teórica. Portanto concluímos que a **mediana** dos valores dos dados do tratamento A diferem significativamente do tratamento B.

Quando `\(n &gt; 20\)`, podemos fazer a aproximação à normal padronizada 

`$$z = \frac{T - \frac{nm}{2}}{\sqrt{nm(n+m+1)/12}} \sim \mathcal{N}(0,1)$$`

---

### Resolvendo no R


```r
y &lt;- c(110,90,100,85,95,110,150,125,120,115)
trat &lt;- gl(2,5,labels=c("A","B"))
wilcox.test(y~trat,alternative="t")
```

```
## Warning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): não é
## possível computar o valor de p exato com o de desempate
```

```
## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  y by trat
## W = 0.5, p-value = 0.01597
## alternative hypothesis: true location shift is not equal to 0
```
---

Utilize o teste de **Wilcoxon Rank Sum** para analisar os dados do conteúdo dos valores do teor de um micronutriente de dois tratamentos A e B.

Hipóteses estatísticas

`$$\begin{cases}
H_0: \tilde{m}_A = \tilde{m}_B  \\
H_1: \tilde{m}_A \neq \tilde{m}_B
\end{cases}$$`



&lt;img src="../img/tnp08.png" width="500px" style="display: block; margin: auto;" /&gt;

---


```r
A &lt;- c(
  0.2, 10.4, 0.3, 10.9, 0.4,11.3, 1.1, 12.4, 2.0, 16.2,
  2.1, 17.6, 3.3, 18.9, 3.8,20.7, 4.5, 24.0, 4.8, 25.4,
  4.9, 40.0, 5.0, 42.2, 5.3,50.0, 7.5, 60.0, 9.8
)

B &lt;- c(
  0.2, 5.4, 0.3, 5.7, 0.4,5.8, 0.7, 7.5, 1.2, 8.7,
  1.5, 8.8, 1.5, 9.1, 1.9,10.3, 2.0, 15.6, 2.4, 16.1,
  2.5, 16.5, 2.8, 16.7, 3.6,20.0, 4.8, 20.7, 4.8, 33.0
)
```


---


```r
wilcox.test(A,B)
```

```
## Warning in wilcox.test.default(A, B): não é possível computar o valor de p
## exato com o de desempate
```

```
## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  A and B
## W = 541, p-value = 0.1096
## alternative hypothesis: true location shift is not equal to 0
```

---

Exemplo de aplicação do teste de **Wilcoxon signed rank test/Mann-Whitney (aproximação normal)**: sementes foram tratadas com um hormônio. O objetivo do experimento foi determinar se o tratamento com o hormônio A poderia resultar em uma alta taxa de germinação. Os dados observados foram 

![](../img/tnp09.png)

![](../img/tnp10.png)

---

### (The Kruskal-Wallis One Way Analysis of Variance by Ranks)

A análise de variância pode ser usada para testar a igualdade de várias médias.

Quando as hipóteses da análise de variância não são satisfeitas, ou seja, **quando as populações** das quais as amostras foram retiradas **não são normais com variâncias iguais**, uma alternativa não-paramétrica para a análise de variância pode ser usada para testar a igualdade de médias.

Várias técnicas não-paramétricas análogas à análise de variância são descritas na literatura, mas a mais bem conhecida é a de **Kruskal-Wallis**.

A técnica será apresentada por meio de um exemplo

---

Suposições: 

  + As doses são amostras aleatórias independentes.  
  + A escala das medidas empregada é pelo menos ordinal.  
  + As distribuições das populações amostradas são idênticas exceto que uma ou mais das populações são compostas de valores que tendem a ser maiores do que nas outras populações.

Hipóteses estatísticas

`$$\begin{cases}
H_0: \text{as distribuições das populações são iguais} \\
H_1: \text{pelo menos uma tende a exibir valores maiores do que pelo menos uma outra população.}
\end{cases}$$`

---

**Exemplo**: O efeito de três doses de um fungicida no número de lagartas na cultura de soja produziram os dados abaixo. A Dose `\(I\)` serviu como controle, enquanto as plantas nas doses `\(II\)` e `\(III\)` foram tratados são doses crescentes do fungicida. 

![](../img/tnp11.png)
---

### Resolvendo no R


```r
g1 &lt;- c(17,20,40,31,35)
g2 &lt;- c(8,7,9,8) 
g3 &lt;- c(2,5,4,3)
```

---


```r
boxplot(g1,col=2,ylim=c(0,40),main="g1",cex.lab=2)
```

![](22-EstatNP_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;

---


```r
boxplot(g2,col=3,ylim=c(0,40),main="g2",cex.lab=2)
```

![](22-EstatNP_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

---


```r
boxplot(g3,col=4,ylim=c(0,40),main="g3",cex.lab=2)
```

![](22-EstatNP_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;

---

**O teste estatístico**

`$$H = \frac{12}{n(n+1)}\sum_{j=1}^k \frac{R^2_j}{n_j}-3(n+1)$$`
em que:
`\(k\)` é o número de grupos, `\(n_j\)` é o número de observações no j-ésimo grupo, `\(n\)` é o número total de observações de todos os grupos e `\(R_j\)` é a soma de postos no j-ésimo grupo.

Aplicando aos dados temos

`$$H = \frac{12}{13(13+1)}\left( \frac{55^2}{5} + \frac{26^2}{4} + \frac{10^2}{4} \right)-3(13+1) = 10,68$$`
Um valor de tabela quando os `\(nj’s\)` são `\(5\)`, `\(4\)`, e `\(4\)` mostra que o "p-value" alcançado é de `\(0,005\)`. Portanto, concluímos que existe uma diferença significativa entre as doses de fungicidas quanto ao número de lagartas na cultura da soja. Para este teste `\(p &lt; 0,005\)`.

---


```r
kruskal.test(list(g1,g2,g3))
```

```
## 
## 	Kruskal-Wallis rank sum test
## 
## data:  list(g1, g2, g3)
## Kruskal-Wallis chi-squared = 10.711, df = 2, p-value = 0.004723
```

---

Para a comparação múltipla, podemos utilizar a função `kruskal` do pacote `agricolae`.


```r
resp &lt;- c(g1,g2,g3)
trat &lt;- rep(1:3,c(5,4,4))
agricolae::kruskal(resp,trat, console = TRUE)
```

```
## 
## Study: resp ~ trat
## Kruskal-Wallis test's
## Ties or no Ties
## 
## Critical Value: 10.71074
## Degrees of freedom: 2
## Pvalue Chisq  : 0.004722713 
## 
## trat,  means of the ranks
## 
##   resp r
## 1 11.0 5
## 2  6.5 4
## 3  2.5 4
## 
## Post Hoc Analysis
## 
## t-Student: 2.228139
## Alpha    : 0.05
## Groups according to probability of treatment differences and alpha level.
## 
## Treatments with the same letter are not significantly different.
## 
##   resp groups
## 1 11.0      a
## 2  6.5      b
## 3  2.5      c
```

---

```
##   resp rank       std r Min Max   Q25  Q50   Q75
## 1 28.6 11.0 9.8132563 5  17  40 20.00 31.0 35.00
## 2  8.0  6.5 0.8164966 4   7   9  7.75  8.0  8.25
## 3  3.5  2.5 1.2909944 4   2   5  2.75  3.5  4.25
```

```
##   resp groups
## 1 11.0      a
## 2  6.5      b
## 3  2.5      c
```

---

### Inferências sobre uma ou duas populações: dados categóricos.

Dados categóricos são medidas de variáveis nominais. Pelo fato de que os valores assumidos pelas variáveis nominais não têm interpretações quantitativas, dados categóricos são melhores descritos usando-se contagens e proporções. 

Em muitas situações os dados são coletados simultaneamente para duas variáveis, e deseja-se testar a hipótese de que as frequências de ocorrências de várias categorias de uma variável são independentes das frequências na segunda variável (Teste de Independência). 

---

**Exemplo**: os dados da tabela abaixo são as frequências de observações de cada uma das `\(4\)` cores de cabelo e cada um dos sexos. Neste exemplo uma amostra de `\(300\)` indivíduos foi analisada para estudar se  a cor do cabelo é esta relacionada com o sexo (Teste de Independência).

![](../img/tnp12.png)

Dizemos que os dados estão arranjados em uma tabela de contingência  2 x 4, ou seja, 2 linhas e 4 colunas 
( r = 2 e c = 4)

Uma tabela com r linhas e c colunas é denominada de  tabela de contingência   `\(r \times c\)`

A hipótese de nulidade para as tabelas de contingência é que as **frequências das observações encontradas nas linhas são independentes das frequências das observações encontradas nas colunas** (ou, que as frequências das colunas são independentes das frequências das linhas). 

`$$\begin{cases}
H_0: \text{a cor do cabelo humano é independente do sexo na população amostrada} \\
H_1: \text{a cor do cabelo humano não é independente do sexo na população amostrada}
\end{cases}$$`

---

### Análise Qui-Quadrado para tabelas de contigência.

O procedimento mais comum para se analisar dados de tabelas de contingências é a estatística Qui-quadrado `\((\chi^2)\)`.

`$$\chi^2 = \sum_{i=1}^r \sum_{j=1}^c\frac{(f_{ij}-\hat{f}_{ij})^2}{\hat{f}_{ij}}$$`

em que `\(f_{ij}\)` é a frequência observada na i-ésima e na j-ésima coluna e `\(\hat{f}_{ij}\)` é a frequência esperada na i-ésima linha e na j-ésima coluna sob `\(H_0\)` verdadeira.

---

#### As frequências esperadas

Para testar `\(H_0\)`, comparamos a frequência observada com frequência esperada, a frequência que esperamos se `\(H_0\)` é verdadeira.

Em uma tabela de contigência  r x c a frequência esperada quando `\(H_0\)` é verdadeira é dada por 

`$$\hat{f}_{ij}=\frac{f_{i+} \times f_{+j}}{n}$$`

ou seja, total da linha i `\((f_{i+})\)`  x total da coluna j `\((f_{+j})\)` dividido pelo total da amostra `\((n)\)`.

---

![](../img/tnp13.png)

`$$\hat{f}_{11} = \frac{87 \times 100}{300} = 29 \cdots \hat{f}_{24} = \frac{25 \times 200}{300} = 16,67$$`

O valor do teste qui-quadrado é dado por:


`$$\chi^2 = \sum_{i=1}^r \sum_{j=1}^c\frac{(f_{ij}-\hat{f}_{ij})^2}{\hat{f}_{ij}} = \frac{(32-29)^2}{29} + \cdots + \frac{(16-16,67)^2}{16,67} = 8,987$$`

Os graus de liberdade são dados por: 

`\(\nu = (r-1)(c-1) = (2-1)(4-1) = 3\)`

---

Assim o valor tabelado `\(\chi^2_{(3;\;0,05)} = 7,815\)`

Portanto rejeita-se `\(H_0\)`, `\(\chi^2_{calc.}  &gt;  \chi^2_{tab.} ( p = 0,029)\)`. O teste é significativo (p&lt;0,05) "a cor do cabelo humano não é independente do sexo.


```r
tab &lt;- matrix(c(32,55,43,65,16,64,9,16),nrow = 2)
tab
```

```
##      [,1] [,2] [,3] [,4]
## [1,]   32   43   16    9
## [2,]   55   65   64   16
```


```r
chisq.test(tab)
```

```
## 
## 	Pearson's Chi-squared test
## 
## data:  tab
## X-squared = 8.9872, df = 3, p-value = 0.02946
```

---

Tabela de valores esperados

```r
qui_quadrado &lt;- chisq.test(tab)
qui_quadrado$expected
```

```
##      [,1] [,2]     [,3]      [,4]
## [1,]   29   36 26.66667  8.333333
## [2,]   58   72 53.33333 16.666667
```

---

### Teste de Homogeneidade

Se as colunas ou as linhas de uma tabela de contingência representam amostras aleatórias de populações independentes, então a hipótese é tipicamente expressa como comparações de proporções.

Por exemplo, para determinar o possível efeito de um tratamento químico na proporção semente/germinação, `\(100\)` sementes quimicamente tratadas e `\(150\)` não tratadas são analisadas. Os números de sementes que germinaram são apresentados na tabela a seguir. Os dados fornecem fortes evidências de que a proporção de sementes germinadas é diferente para as tratadas e as não tratadas?

Considere `\(p_1\)` e `\(p_2\)` as proporções de sementes tratadas e não tratadas quimicamente, respectivamente. Desejamos testar as hipóteses:

`\(H_0\)` : a proporção de sementes tratadas quimicamente é a mesma da proporção das não tratadas `\(( H_0: p_1   =  p_2 )\)`   
`\(H_1\)` : a proporção de sementes tratadas quimicamente não é a mesma da proporção das não tratadas `\(( H_1: p_1 \neq  p_2 )\)`.

---

 |Germinadas	|  Não Germinadas	| Total
:--- |:---: | :---: | :---: |
Tratadas	| 84	| 16	| 100  
Não tratadas| 	132	| 18| 	150  
Total	| 216	| 34| 	250  


Para analisar esta tabela `\(2 \times 2\)`, utilizamos a fórmula

`$$\chi^2 = \frac{n(f_{11}f_{22}-f_{12}f_{21})^2}{r_1r_2c_1c_2} = 0,817 \text{ com } p=0,3661$$`

Aplicando a correção de Yates para continuidade, a fórmula acima fica.


`$$\chi^2 = \frac{n(|f_{11}f_{22}-f_{12}f_{21}|-\frac{n}{2})^2}{r_1r_2c_1c_2}$$`

No exemplo fica

`$$\chi^2 = \frac{150(|(84)(18)-(16)(132)|-\frac{250}{2})^2}{(100)(150)(216)(34)} = 0,512$$`
`$$\nu = 1 \text{ e } \chi^2 = 3,841 \text{ com } p = 0,4743$$`
Portanto, não se rejeita-se `\(H_0\)`. 

---


```r
# teste qui-quadrado
tab2 &lt;- matrix(c(84,16,132,18),nrow=2)
chisq.test(tab2,correct=F)    # em correção de Yates
```

```
## 
## 	Pearson's Chi-squared test
## 
## data:  tab2
## X-squared = 0.81699, df = 1, p-value = 0.3661
```

```r
chisq.test(tab2,correct=T)    # com correção de Yates
```

```
## 
## 	Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  tab2
## X-squared = 0.51204, df = 1, p-value = 0.4743
```

---


```r
fisher.test(tab2)   # teste exato de fisher
```

```
## 
## 	Fisher's Exact Test for Count Data
## 
## data:  tab2
## p-value = 0.4517
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.3248799 1.5933461
## sample estimates:
## odds ratio 
##  0.7169055
```

---

**Exemplo**:  Em uma amostra de `\(50\)` ratos, todos da mesma espécie, foram separados em dois grupos de `\(25\)`. Os membros de um dos grupos foram alimentados com uma substância que pode ter um efeito na ocorrência de parasitas intestinal, e o segundo grupo não recebeu a alimentação com a substância.   

`\(H_0\)` :  a incidência de infeção de parasita em ratos é a mesma no grupo tratado ou não.  
`\(H_1\)` : a incidência de infeção de parasita em ratos não é a mesma no grupo tratado ou não  

  |Sem a subs.	|  Com a subs.	| Total
:--- |:---: | :---: | :---: |
Com parasita	| 15	| 9	| 24  
Sem parasita | 	10	| 16| 	26  
Total	| 25	| 25| 	50  

---

Aplicando a fórmula com a correção de continuidade de Yates, temos

`$$\chi^2 = \frac{50(|(15)(16)-(9)(10)|-\frac{50}{2})^2}{(25)(25)(24)(26)} = 2,003$$`

`$$\nu = 1 \text{ e } \chi^2_{(1;\;0,05)} = 3,841$$`
Portanto, não rejeita-se `\(H_0\)`, com valor de `\(p =0,16\)` 

---

#### Resolvendo no R


```r
# teste qui-quadrado
tab2 &lt;- matrix(c(15,9,10,16),nrow=2)
qchisq(p = 1-0.05,1) # quantil para 0.95
```

```
## [1] 3.841459
```



```r
chisq.test(tab2,correct=F)    
```

```
## 
## 	Pearson's Chi-squared test
## 
## data:  tab2
## X-squared = 2.8846, df = 1, p-value = 0.08943
```

```r
chisq.test(tab2,correct=T)
```

```
## 
## 	Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  tab2
## X-squared = 2.0032, df = 1, p-value = 0.157
```

---


```r
fisher.test(tab2)   
```

```
## 
## 	Fisher's Exact Test for Count Data
## 
## data:  tab2
## p-value = 0.1564
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.7405287 9.7794152
## sample estimates:
## odds ratio 
##   2.612614
```

---

### Contagens requeridas para o teste Qui-quadrado

Podemos usar o teste qui-quadrado com segurança quando não mais que de `\(20\%\)`  de contagens esperadas são menores que `\(5\)` e todas as contagens esperadas individuais são iguais a, ou superiores a `\(1\)`. Em particular, todas as quatros contagens esperadas em uma tabela `\(2 \times 2\)` devem ser iguais ou superiores a `\(5\)`.

Nestes casos o teste Exato de Fisher *(Fisher´s exact test)* é geralmente preferível ao teste Qui-Quadrado, especialmente quando as frequências são pequenas. (dados muito esparsos)  

---

Exemplo: Habilidade de cobras de se fixar

 |resistiram	|  não resistiram	| Total
:--- |:---: | :---: | :---: |
espécie 1	| 12	| 7	| 19  
espécie 2 | 	2	| 9| 	11  
Total	| 14	| 16| 	30  

`\(H_0:\)` a habilidade das cobras de resistir a correte não é diferente nas duas espécies.  
`\(H_1:\)` a habilidade das cobras de resistir a correte é diferente nas duas espécies.

`$$\chi^2 = \frac{20(|(12)(9)-(2)(7)|-\frac{20}{2})^2}{(14)(16)(19)(11)} = 3,999$$`

`$$\nu = 1 \text{ e } \chi^2_{(1;\;0,05)} = 3,841$$`



Portanto, não rejeitamos `\(H_0\)`.

---


```r
#teste exato de Fisher
tab3 &lt;- matrix(c(12,2,7,9),nrow=2)
tab3
```

```
##      [,1] [,2]
## [1,]   12    7
## [2,]    2    9
```

```r
chisq.test(tab3,correct=T) 
```

```
## 
## 	Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  tab3
## X-squared = 3.9993, df = 1, p-value = 0.04552
```

```r
fisher.test(tab3)
```

```
## 
## 	Fisher's Exact Test for Count Data
## 
## data:  tab3
## p-value = 0.02589
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##   1.053152 87.138198
## sample estimates:
## odds ratio 
##   7.166131
```

---

### Restrições do uso do teste `\(\chi^2\)`

Por razões teóricas:
  + os testes vistos aplicam-se sem restrição se todas as fe’s  são maiores do que 5;

  + nas tabelas de contingência com mais de `\(1\)` grau de liberdade, se poucas fe’s são menores do que `\(5\)` (20% ou menos das células), pode-se aplicar o teste `\(\chi^2\)`, desde que  as fe’s sejam maiores ou iguais 1. Se estas condições não se verificam, pode-se juntar categorias adjacentes de modo a aumentar as fe’s;

- os testes somente devem ser aplicados aos dados observados e nunca com as proporções ou porcentagens oriundas dos mesmos. 



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
